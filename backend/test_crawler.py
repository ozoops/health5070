import os
import sys
from crawler import DongACrawler
from database import init_db

# í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ë¥¼ sys.pathì— ì¶”ê°€í•˜ì—¬ ëª¨ë“ˆì„ ì„í¬íŠ¸í•  ìˆ˜ ìˆë„ë¡ í•¨
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def run_test_crawl(article_limit=10):
    """
    í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ ì œí•œëœ ìˆ˜ì˜ ê¸°ì‚¬ë¥¼ í¬ë¡¤ë§í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    """
    print(f"ğŸš€ {article_limit}ê°œ ê¸°ì‚¬ í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

    # 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”
    conn = init_db()
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # 2. í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = DongACrawler()
    print("ğŸ•·ï¸ í¬ë¡¤ëŸ¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. í—¬ìŠ¤ë™ì•„ì—ì„œ ê¸°ì‚¬ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤...")

    # 3. ê¸°ì‚¬ í¬ë¡¤ë§
    articles = crawler.crawl_health_articles()

    if not articles:
        print("âš ï¸ í¬ë¡¤ë§ ì¤‘ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        conn.close()
        return

    print(f"ğŸ“° ì´ {len(articles)}ê°œì˜ ê¸°ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ìµœëŒ€ {article_limit}ê°œë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")

    # 4. í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê¸°ì‚¬ ìˆ˜ë¥¼ 10ê°œë¡œ ì œí•œ
    articles_to_save = articles[:article_limit]

    # 5. ì œí•œëœ ìˆ˜ì˜ ê¸°ì‚¬ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
    print(f"ğŸ’¾ {len(articles_to_save)}ê°œì˜ ê¸°ì‚¬ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤...")
    new_count, age_relevant_count = crawler.save_articles(articles_to_save, conn)

    # 6. ê²°ê³¼ ì¶œë ¥
    print("\n--- í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ ìš”ì•½ ---")
    print(f"âœ¨ {new_count}ê°œì˜ ìƒˆë¡œìš´ ê¸°ì‚¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ¯ 50-70ëŒ€ ê´€ë ¨ ê¸°ì‚¬ë¥¼ {age_relevant_count}ê°œ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
    print("--------------------------")

    # 7. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
    conn.close()
    print("âœ… í…ŒìŠ¤íŠ¸ í¬ë¡¤ë§ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    run_test_crawl()
